{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Hazem Bin Ryaz Patel (2200550)\n",
    "Class : DAAA/2B/07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import visualkeras\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    MaxPool2D,\n",
    "    Add,\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Normalization, Dense, Conv2D, Dropout, BatchNormalization, ReLU\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "# from sklearn.model_selection import RandomizedSearchCV,KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_r = 42\n",
    "np.random.seed(seed_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./Dataset for CA1 part A\"\n",
    "# image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir + \"/train\",\n",
    "    seed=seed_r,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir + \"/validation\",\n",
    "    seed=seed_r,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir + \"/test\",\n",
    "    seed=seed_r,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    x_train.extend(images.numpy())\n",
    "    y_train.extend(labels.numpy())\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(8, 5), tight_layout=True)\n",
    "\n",
    "for label, subplot in enumerate(ax.ravel()):\n",
    "    subplot.axis(\"off\")\n",
    "    subplot.imshow(\n",
    "        x_train[y_train == label][\n",
    "            np.random.randint(0, len(x_train[y_train == label]))\n",
    "        ].astype(\"uint8\"),\n",
    "        cmap=\"Greys\",\n",
    "    )\n",
    "    subplot.set_title(class_names[label])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for mislabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(15, 10, figsize=(15, 20))\n",
    "for i in range(15):\n",
    "    images = x_train[np.squeeze(y_train == i)].astype(\"uint8\")\n",
    "    random_index = np.random.choice(images.shape[0], 15, replace=False)\n",
    "    images = images[random_index]\n",
    "    label = class_names[i]\n",
    "    for j in range(10):\n",
    "        subplot = ax[i, j]\n",
    "        subplot.axis(\"off\")\n",
    "        subplot.imshow(images[j], cmap='Greys')\n",
    "        subplot.set_title(label, fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : There isn't any mislabelling, so we don't need to re-label any of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(20, 10))\n",
    "\n",
    "for idx, subplot in enumerate(ax.ravel()):\n",
    "    avg_image = np.mean(x_train[np.squeeze(y_train == idx)], axis=0) / 255\n",
    "    subplot.imshow(avg_image, cmap=\"Greys\")\n",
    "    subplot.set_title(f\"{class_names[idx]}\")\n",
    "    subplot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them you can kinda see the color, but most of them is just a ball of green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(labels, counts):\n",
    "    print(f\"{class_names[label]}: {count}\")\n",
    "\n",
    "plt.barh(labels, counts, tick_label=class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling with the use of Data Augmentations\n",
    "One of the things that is very obvious that neeeds to be adjusted is the imabalance of classes\n",
    "The method that I've chose to address this is oversampling of the classes which are imbalanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy access to images and labels: You can directly access any image and its label using the tensor reference as the key.\n",
    "Simplified code: The code is more straightforward and easier to understand.\n",
    "Disadvantages:\n",
    "\n",
    "Memory usage: Unbatching the dataset and storing it in a dictionary can consume more memory, especially for large datasets.\n",
    "Slower execution: Iterating over the entire unbatched dataset to create the dictionary can be slower than iterating over a batched dataset.\n",
    "Directly iterating over a batched dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {tf.Tensor.ref(img): label for img, label in train_ds.unbatch()}\n",
    "\n",
    "def data_augmentation(data):\n",
    "    imageArr = []\n",
    "    for images in data:\n",
    "        image = tf.image.random_flip_left_right(images)\n",
    "        image = tf.image.random_crop(\n",
    "            image, size=(224,224,3)\n",
    "        )\n",
    "        imageArr.append(tf.reshape(image, (224, 224, 3)))\n",
    "    return np.array(imageArr)\n",
    "\n",
    "def augment_undersampled_vegs(img_labels, X_train, y_train):\n",
    "    undersampled_labels = []\n",
    "    undersampled_vegs = []\n",
    "    for veg_type in img_labels:\n",
    "        # Get all images of a veg type\n",
    "        veg_images = [img.deref() for img, label in train_dict.items() if label == veg_type]\n",
    "        veg_labels = [label for img, label in train_dict.items() if label == veg_type]\n",
    "\n",
    "        if veg_type == img_labels[0]:\n",
    "            undersampled_vegs = veg_images\n",
    "            undersampled_labels = veg_labels     \n",
    "        else : \n",
    "            undersampled_vegs = np.concatenate((undersampled_vegs, veg_images), axis=0)\n",
    "            undersampled_labels = np.concatenate((undersampled_labels, veg_labels), axis=0)\n",
    "\n",
    "        veg_train_aug = data_augmentation(undersampled_vegs)\n",
    "    \n",
    "    print(veg_train_aug.shape)\n",
    "    print(undersampled_labels.shape)\n",
    "\n",
    "    X_train = np.concatenate((X_train, veg_train_aug), axis=0)\n",
    "    y_train = np.concatenate((y_train, undersampled_labels), axis=0)\n",
    "    return X_train, y_train\n",
    "\n",
    "# veg_types are the labels of the vegetables which are undersampled\n",
    "veg_types = [2,5,6,7,10,11,13]\n",
    "\n",
    "X_train_aug, y_train_aug = augment_undersampled_vegs(veg_types, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Images\n",
    "- Re-batch X_train_aug and y_train_aug\n",
    "- Grayscale, Normalize and Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "    train_ds_rebatch = tf.data.Dataset.from_tensor_slices((X_train_aug, y_train_aug))\n",
    "    train_ds_rebatch = train_ds_rebatch.shuffle(buffer_size=len(X_train_aug))  # Shuffle the data\n",
    "    train_ds_rebatch = train_ds_rebatch.batch(32)\n",
    "\n",
    "# normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "# ds = ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "def process(ds):\n",
    "    ds = ds.map(lambda x, y: (tf.image.rgb_to_grayscale(x), y))\n",
    "    ds = ds.map(lambda x, y: (tf.image.resize(x, (128, 128)), y))\n",
    "    return ds\n",
    "\n",
    "train_ds_128 = process(train_ds_rebatch)\n",
    "val_ds_128 = process(val_ds)\n",
    "test_ds_128 = process(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA After Resizing, Grayscaling & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_128 = []\n",
    "y_train_128 = []\n",
    "\n",
    "for images, labels in train_ds_128:\n",
    "    x_train_128.extend(images.numpy())\n",
    "    y_train_128.extend(labels.numpy())\n",
    "\n",
    "x_train_128 = np.array(x_train_128)\n",
    "y_train_128 = np.array(y_train_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(8,5), tight_layout=True)\n",
    "\n",
    "for idx, subplot in enumerate(ax.ravel()):\n",
    "    avg_image = np.mean(x_train_128[np.squeeze(y_train_128 == idx)], axis=0) / 255\n",
    "    subplot.imshow(avg_image, cmap=\"Greys\")\n",
    "    subplot.set_title(f\"{class_names[idx]}\")\n",
    "    subplot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(8, 5), tight_layout=True)\n",
    "\n",
    "for label, subplot in enumerate(ax.ravel()):\n",
    "    subplot.axis(\"off\")\n",
    "    subplot.imshow(\n",
    "        x_train_128[y_train_128 == label][\n",
    "            np.random.randint(0, len(x_train_128[y_train_128 == label]))\n",
    "        ],\n",
    "        cmap=\"Greys\",\n",
    "    )\n",
    "    subplot.set_title(class_names[label])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for CNN 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds_128 = train_ds_128.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds_128 = val_ds_128.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_128():  # learning_rate, activation\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(64, 3, input_shape=(128, 128, 1), padding=\"same\", activation=\"relu\")\n",
    "    )\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Flatten the feature map\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add the fully connected layers\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(15, activation=\"softmax\"))\n",
    "\n",
    "    # Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model_128 = create_model_128()\n",
    "history_128 = model_128.fit(\n",
    "    train_ds_128, \n",
    "    validation_data=val_ds_128, \n",
    "    epochs=30, \n",
    "    batch_size=64,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min'), \n",
    "    ModelCheckpoint('model_128.h5', monitor='val_loss', save_best_only=True, verbose=1)]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "plot_model(model_128, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_128.evaluate(test_ds_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_128.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history_128.history['loss'])\n",
    "plt.plot(history_128.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for 128 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_128_model(dropout, batchsize, dense):\n",
    "    opt = Adam(lr=0.01)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(31, 31, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(31, 31, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(128, activation='relu'))  # hidden layer\n",
    "    model.add(Dense(dense, activation=\"softmax\"))  # output layer\n",
    "\n",
    "    # Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(train_ds_128, validation_data=val_ds_128, epochs=30, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    # Evaluate model on unseen data\n",
    "    scores = model.evaluate(test_ds)\n",
    "    testError = 100-scores[1]*100\n",
    "\n",
    "    return history, scores[1], testError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(batch_sizes, dropouts, dense_sizes):\n",
    "    # Store the results\n",
    "    results = []\n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for batch_size in batch_sizes:\n",
    "        for dropout in dropouts:\n",
    "            for dense_size in dense_sizes:\n",
    "                history, accuracy, test_error = tune_128_model(batch_size, dropout, dense_size)\n",
    "                \n",
    "                # Store the results\n",
    "                results.append({\n",
    "                    'batch_size': batch_size,\n",
    "                    'dropout': dropout,\n",
    "                    'dense_size': dense_size,\n",
    "                    'accuracy': accuracy,\n",
    "                    'test_error': test_error\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define the hyperparameters to test\n",
    "batch_sizes = [32, 64, 128]\n",
    "dropouts = np.arange(0.1,0.5,0.8)\n",
    "dense_sizes = [32,64,128,256]\n",
    "\n",
    "# Run the grid search\n",
    "results = grid_search(batch_sizes, dropouts, dense_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in model from .h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
