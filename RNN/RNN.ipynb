{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional, GRU, SimpleRNN\n",
    "from keras.layers import Dropout, LayerNormalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Quotes\n",
      "0  Embrace the beauty of every sunrise; it's a fr...\n",
      "1  Embrace challenges; they are the stepping ston...\n",
      "2  Embrace the rhythm of life and let it dance th...\n",
      "3  Embrace kindness, for it has the power to chan...\n",
      "4  Embrace the journey, for it leads to the desti...\n",
      "Data shape: (1000, 1)\n",
      "Missing values: Quotes    0\n",
      "dtype: int64\n",
      "                                                   Quotes\n",
      "count                                                1000\n",
      "unique                                                890\n",
      "top     Radiate acceptance, and find peace in embracin...\n",
      "freq                                                    5\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "print(data.head())\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Missing values:\", data.isnull().sum())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data = list(data['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'your': 3,\n",
       " 'and': 4,\n",
       " 'a': 5,\n",
       " 'is': 6,\n",
       " 'in': 7,\n",
       " 'for': 8,\n",
       " 'let': 9,\n",
       " 'to': 10,\n",
       " 'it': 11,\n",
       " 'be': 12,\n",
       " 'every': 13,\n",
       " 'our': 14,\n",
       " 'you': 15,\n",
       " 'that': 16,\n",
       " 'embrace': 17,\n",
       " \"life's\": 18,\n",
       " 'this': 19,\n",
       " 'are': 20,\n",
       " 'morning': 21,\n",
       " 'with': 22,\n",
       " 'radiate': 23,\n",
       " 'dance': 24,\n",
       " 'heart': 25,\n",
       " 'believe': 26,\n",
       " 'yourself': 27,\n",
       " 'through': 28,\n",
       " \"planet's\": 29,\n",
       " 'will': 30,\n",
       " 'life': 31,\n",
       " 'love': 32,\n",
       " 'they': 33,\n",
       " \"singapore's\": 34,\n",
       " 'kindness': 35,\n",
       " 'power': 36,\n",
       " 'from': 37,\n",
       " 'dreams': 38,\n",
       " 'we': 39,\n",
       " 'soul': 40,\n",
       " 'symphony': 41,\n",
       " 'act': 42,\n",
       " 'find': 43,\n",
       " 'gratitude': 44,\n",
       " 'singapore': 45,\n",
       " 'world': 46,\n",
       " 'strength': 47,\n",
       " 'light': 48,\n",
       " 'beauty': 49,\n",
       " 'journey': 50,\n",
       " 'nature': 51,\n",
       " 'joy': 52,\n",
       " 'planet': 53,\n",
       " 'canvas': 54,\n",
       " 'colors': 55,\n",
       " 'way': 56,\n",
       " 'whispers': 57,\n",
       " 'where': 58,\n",
       " 'potential': 59,\n",
       " 'hope': 60,\n",
       " 'testament': 61,\n",
       " 'resilience': 62,\n",
       " 'towards': 63,\n",
       " 'true': 64,\n",
       " 'new': 65,\n",
       " 'compassion': 66,\n",
       " 'beacon': 67,\n",
       " 'actions': 68,\n",
       " 'future': 69,\n",
       " 'spirit': 70,\n",
       " 'step': 71,\n",
       " 'change': 72,\n",
       " 'wisdom': 73,\n",
       " 'moments': 74,\n",
       " 'promise': 75,\n",
       " 'garden': 76,\n",
       " 'sunrise': 77,\n",
       " 'laughter': 78,\n",
       " 'story': 79,\n",
       " 'hearts': 80,\n",
       " 'day': 81,\n",
       " 'hold': 82,\n",
       " 'an': 83,\n",
       " 'tapestry': 84,\n",
       " 'heartbeat': 85,\n",
       " 'compass': 86,\n",
       " 'gift': 87,\n",
       " 'force': 88,\n",
       " 'inner': 89,\n",
       " 'each': 90,\n",
       " 'on': 91,\n",
       " 'holds': 92,\n",
       " 'destiny': 93,\n",
       " 'into': 94,\n",
       " 'self': 95,\n",
       " 'legacy': 96,\n",
       " 'when': 97,\n",
       " 'lion': 98,\n",
       " 'city': 99,\n",
       " 'skyline': 100,\n",
       " 'paint': 101,\n",
       " 'challenge': 102,\n",
       " 'determination': 103,\n",
       " 'tranquility': 104,\n",
       " 'others': 105,\n",
       " 'moment': 106,\n",
       " 'forgiveness': 107,\n",
       " 'melody': 108,\n",
       " 'any': 109,\n",
       " 'opportunities': 110,\n",
       " 'seeds': 111,\n",
       " 'within': 112,\n",
       " 'chapters': 113,\n",
       " 'growth': 114,\n",
       " 'purpose': 115,\n",
       " 'authenticity': 116,\n",
       " 'peace': 117,\n",
       " 'brings': 118,\n",
       " 'rhythm': 119,\n",
       " 'universe': 120,\n",
       " 'can': 121,\n",
       " 'reality': 122,\n",
       " 'overcome': 123,\n",
       " 'empathy': 124,\n",
       " 'serenity': 125,\n",
       " 'leave': 126,\n",
       " 'vibrant': 127,\n",
       " 'aspirations': 128,\n",
       " 'breath': 129,\n",
       " 'watch': 130,\n",
       " 'blessings': 131,\n",
       " 'rain': 132,\n",
       " 'music': 133,\n",
       " 'beginnings': 134,\n",
       " 'treasure': 135,\n",
       " 'have': 136,\n",
       " 'shape': 137,\n",
       " 'possibility': 138,\n",
       " 'positivity': 139,\n",
       " 'create': 140,\n",
       " 'carries': 141,\n",
       " 'bridge': 142,\n",
       " 'path': 143,\n",
       " 'nurtured': 144,\n",
       " 'us': 145,\n",
       " 'open': 146,\n",
       " 'reminder': 147,\n",
       " 'challenges': 148,\n",
       " 'has': 149,\n",
       " 'joyful': 150,\n",
       " 'more': 151,\n",
       " 'transform': 152,\n",
       " 'brighter': 153,\n",
       " 'foundation': 154,\n",
       " 'confidence': 155,\n",
       " 'guides': 156,\n",
       " 'guiding': 157,\n",
       " 'progress': 158,\n",
       " 'painted': 159,\n",
       " 'threads': 160,\n",
       " 'opportunity': 161,\n",
       " 'conservation': 162,\n",
       " 'fresh': 163,\n",
       " 'key': 164,\n",
       " 'success': 165,\n",
       " 'carry': 166,\n",
       " 'smile': 167,\n",
       " 'up': 168,\n",
       " 'its': 169,\n",
       " 'connection': 170,\n",
       " 'diversity': 171,\n",
       " 'touch': 172,\n",
       " 'masterpiece': 173,\n",
       " 'possibilities': 174,\n",
       " 'around': 175,\n",
       " 'sanctuary': 176,\n",
       " 'boundless': 177,\n",
       " 'star': 178,\n",
       " 'take': 179,\n",
       " 'shine': 180,\n",
       " 'by': 181,\n",
       " 'flourishes': 182,\n",
       " \"park's\": 183,\n",
       " 'hear': 184,\n",
       " 'stillness': 185,\n",
       " 'than': 186,\n",
       " 'experience': 187,\n",
       " 'wind': 188,\n",
       " 'lead': 189,\n",
       " 'magic': 190,\n",
       " 'energy': 191,\n",
       " 'being': 192,\n",
       " 'passions': 193,\n",
       " 'truest': 194,\n",
       " 'presence': 195,\n",
       " 'behind': 196,\n",
       " 'courage': 197,\n",
       " 'essence': 198,\n",
       " 'ignites': 199,\n",
       " 'grace': 200,\n",
       " 'echoes': 201,\n",
       " 'forward': 202,\n",
       " 'woven': 203,\n",
       " \"someone's\": 204,\n",
       " 'generosity': 205,\n",
       " 'innovation': 206,\n",
       " 'sunset': 207,\n",
       " 'pulau': 208,\n",
       " 'paints': 209,\n",
       " \"reserve's\": 210,\n",
       " 'present': 211,\n",
       " 'how': 212,\n",
       " 'language': 213,\n",
       " 'even': 214,\n",
       " 'darkest': 215,\n",
       " 'days': 216,\n",
       " 'unfold': 217,\n",
       " 'song': 218,\n",
       " 'turns': 219,\n",
       " 'adventure': 220,\n",
       " 'stories': 221,\n",
       " 'word': 222,\n",
       " 'transformation': 223,\n",
       " 'souls': 224,\n",
       " 'faith': 225,\n",
       " 'inspire': 226,\n",
       " 'abundance': 227,\n",
       " 'mark': 228,\n",
       " 'spark': 229,\n",
       " 'endless': 230,\n",
       " 'storms': 231,\n",
       " 'flight': 232,\n",
       " 'stronger': 233,\n",
       " 'dream': 234,\n",
       " 'source': 235,\n",
       " 'experiences': 236,\n",
       " 'made': 237,\n",
       " 'brightens': 238,\n",
       " 'connects': 239,\n",
       " 'tall': 240,\n",
       " 'reminds': 241,\n",
       " 'warmth': 242,\n",
       " 'dawn': 243,\n",
       " 'biodiversity': 244,\n",
       " 'protect': 245,\n",
       " 'offers': 246,\n",
       " 'leads': 247,\n",
       " 'words': 248,\n",
       " 'simplicity': 249,\n",
       " 'secrets': 250,\n",
       " 'positive': 251,\n",
       " 'well': 252,\n",
       " 'stars': 253,\n",
       " 'intuition': 254,\n",
       " 'humanity': 255,\n",
       " 'driving': 256,\n",
       " 'inspiration': 257,\n",
       " 'discovery': 258,\n",
       " 'care': 259,\n",
       " 'expression': 260,\n",
       " 'armor': 261,\n",
       " 'curiosity': 262,\n",
       " 'enthusiasm': 263,\n",
       " 'echo': 264,\n",
       " 'capable': 265,\n",
       " 'obstacle': 266,\n",
       " 'worthy': 267,\n",
       " 'discover': 268,\n",
       " 'composed': 269,\n",
       " 'blooms': 270,\n",
       " 'strokes': 271,\n",
       " 'mosaic': 272,\n",
       " 'classroom': 273,\n",
       " 'learn': 274,\n",
       " 'book': 275,\n",
       " 'written': 276,\n",
       " 'knows': 277,\n",
       " 'happiness': 278,\n",
       " 'creates': 279,\n",
       " 'faced': 280,\n",
       " 'creating': 281,\n",
       " 'start': 282,\n",
       " 'effort': 283,\n",
       " 'friendship': 284,\n",
       " 'formed': 285,\n",
       " 'choice': 286,\n",
       " 'brushstroke': 287,\n",
       " 'thought': 288,\n",
       " 'liberation': 289,\n",
       " 'investment': 290,\n",
       " 'tribute': 291,\n",
       " 'marvel': 292,\n",
       " 'gentle': 293,\n",
       " 'diverse': 294,\n",
       " 'bukit': 295,\n",
       " 'unity': 296,\n",
       " 'coastal': 297,\n",
       " \"nature's\": 298,\n",
       " 'time': 299,\n",
       " 'truly': 300,\n",
       " 'unlocking': 301,\n",
       " 'free': 302,\n",
       " 'ever': 303,\n",
       " 'beautiful': 304,\n",
       " 'genuine': 305,\n",
       " 'guide': 306,\n",
       " 'what': 307,\n",
       " 'lived': 308,\n",
       " 'pages': 309,\n",
       " 'heal': 310,\n",
       " 'flow': 311,\n",
       " 'learning': 312,\n",
       " 'seasons': 313,\n",
       " 'reflection': 314,\n",
       " 'creativity': 315,\n",
       " 'give': 316,\n",
       " 'bring': 317,\n",
       " 'lives': 318,\n",
       " 'solace': 319,\n",
       " 'voice': 320,\n",
       " 'precious': 321,\n",
       " 'adventures': 322,\n",
       " 'humility': 323,\n",
       " 'fuel': 324,\n",
       " 'become': 325,\n",
       " 'propels': 326,\n",
       " 'character': 327,\n",
       " 'greatness': 328,\n",
       " 'giving': 329,\n",
       " 'treasures': 330,\n",
       " 'good': 331,\n",
       " 'lights': 332,\n",
       " 'miracles': 333,\n",
       " 'make': 334,\n",
       " 'created': 335,\n",
       " 'celebration': 336,\n",
       " 'reveal': 337,\n",
       " 'tended': 338,\n",
       " 'cleanses': 339,\n",
       " 'resonates': 340,\n",
       " 'go': 341,\n",
       " 'understanding': 342,\n",
       " 'no': 343,\n",
       " 'wings': 344,\n",
       " 'waves': 345,\n",
       " 'wonder': 346,\n",
       " 'beneath': 347,\n",
       " 'goodness': 348,\n",
       " 'setup': 349,\n",
       " 'or': 350,\n",
       " 'person': 351,\n",
       " 'encouragement': 352,\n",
       " 'memories': 353,\n",
       " 'chapter': 354,\n",
       " 'encounter': 355,\n",
       " 'gem': 356,\n",
       " 'treasury': 357,\n",
       " 'harmony': 358,\n",
       " 'charm': 359,\n",
       " 'stands': 360,\n",
       " 'nation': 361,\n",
       " \"ubin's\": 362,\n",
       " 'vision': 363,\n",
       " 'heritage': 364,\n",
       " 'labrador': 365,\n",
       " 'vitality': 366,\n",
       " 'breathtaking': 367,\n",
       " 'lungs': 368,\n",
       " 'leaves': 369,\n",
       " 'arms': 370,\n",
       " 'welcome': 371,\n",
       " \"it's\": 372,\n",
       " 'stepping': 373,\n",
       " 'greatest': 374,\n",
       " 'one': 375,\n",
       " 'fears': 376,\n",
       " 'nourishes': 377,\n",
       " 'sets': 378,\n",
       " 'past': 379,\n",
       " 'louder': 380,\n",
       " 'own': 381,\n",
       " 'imagination': 382,\n",
       " 'enough': 383,\n",
       " 'keys': 384,\n",
       " 'warm': 385,\n",
       " 'wounds': 386,\n",
       " 'brilliance': 387,\n",
       " 'community': 388,\n",
       " 'grateful': 389,\n",
       " 'night': 390,\n",
       " 'mirror': 391,\n",
       " 'tomorrow': 392,\n",
       " 'wounded': 393,\n",
       " 'resides': 394,\n",
       " 'harmonious': 395,\n",
       " 'most': 396,\n",
       " 'illuminates': 397,\n",
       " 'those': 398,\n",
       " 'shields': 399,\n",
       " 'bitterness': 400,\n",
       " 'embracing': 401,\n",
       " 'haven': 402,\n",
       " 'like': 403,\n",
       " 'heals': 404,\n",
       " 'gifts': 405,\n",
       " 'fragrance': 406,\n",
       " 'chorus': 407,\n",
       " 'lighthouse': 408,\n",
       " 'follow': 409,\n",
       " 'soar': 410,\n",
       " 'break': 411,\n",
       " 'many': 412,\n",
       " 'extraordinary': 413,\n",
       " 'them': 414,\n",
       " 'passion': 415,\n",
       " 'share': 416,\n",
       " 'pursuit': 417,\n",
       " \"heart's\": 418,\n",
       " 'desires': 419,\n",
       " 'existence': 420,\n",
       " 'unique': 421,\n",
       " 'hues': 422,\n",
       " 'acts': 423,\n",
       " 'reminders': 424,\n",
       " 'gardens': 425,\n",
       " 'cherish': 426,\n",
       " 'full': 427,\n",
       " 'leaving': 428,\n",
       " 'write': 429,\n",
       " 'intention': 430,\n",
       " 'letting': 431,\n",
       " 'their': 432,\n",
       " 'sea': 433,\n",
       " 'ripple': 434,\n",
       " 'home': 435,\n",
       " 'fuels': 436,\n",
       " 'soothes': 437,\n",
       " 'wonders': 438,\n",
       " 'embodiment': 439,\n",
       " 'setback': 440,\n",
       " 'comeback': 441,\n",
       " 'bloom': 442,\n",
       " 'taken': 443,\n",
       " 'whether': 444,\n",
       " 'painful': 445,\n",
       " 'transitions': 446,\n",
       " 'directed': 447,\n",
       " 'indomitable': 448,\n",
       " 'wave': 449,\n",
       " 'witnessing': 450,\n",
       " 'cherished': 451,\n",
       " 'bay': 452,\n",
       " 'ambition': 453,\n",
       " 'modernity': 454,\n",
       " 'perfect': 455,\n",
       " \"chinatown's\": 456,\n",
       " 'pulse': 457,\n",
       " 'waiting': 458,\n",
       " \"gardens'\": 459,\n",
       " 'history': 460,\n",
       " 'sky': 461,\n",
       " 'quiet': 462,\n",
       " \"nation's\": 463,\n",
       " 'jurong': 464,\n",
       " 'wildlife': 465,\n",
       " 'sungei': 466,\n",
       " 'buloh': 467,\n",
       " 'wetland': 468,\n",
       " 'landscapes': 469,\n",
       " 'rugged': 470,\n",
       " 'witness': 471,\n",
       " 'face': 472,\n",
       " 'ancient': 473,\n",
       " 'survival': 474,\n",
       " 'species': 475,\n",
       " 'reefs': 476,\n",
       " 'cradle': 477,\n",
       " 'artistry': 478,\n",
       " 'rustle': 479,\n",
       " 'springs': 480,\n",
       " \"day's\": 481,\n",
       " 'fills': 482,\n",
       " 'air': 483,\n",
       " 'clarity': 484,\n",
       " 'fill': 485,\n",
       " 'chance': 486,\n",
       " 'stones': 487,\n",
       " 'at': 488,\n",
       " 'uniqueness': 489,\n",
       " 'only': 490,\n",
       " 'multiplies': 491,\n",
       " 'chains': 492,\n",
       " 'could': 493,\n",
       " 'small': 494,\n",
       " 'blueprints': 495,\n",
       " 'cornerstone': 496,\n",
       " 'gateway': 497,\n",
       " 'chest': 498,\n",
       " 'patience': 499,\n",
       " 'far': 500,\n",
       " 'birthplace': 501,\n",
       " 'thoughts': 502,\n",
       " 'nights': 503,\n",
       " 'mend': 504,\n",
       " 'everyday': 505,\n",
       " 'alchemy': 506,\n",
       " 'conductor': 507,\n",
       " 'cosmos': 508,\n",
       " 'kind': 509,\n",
       " 'remind': 510,\n",
       " 'emotions': 511,\n",
       " 'ordinary': 512,\n",
       " 'mind': 513,\n",
       " 'cycles': 514,\n",
       " 'weave': 515,\n",
       " 'cleanse': 516,\n",
       " 'fulfilled': 517,\n",
       " 'burdens': 518,\n",
       " 'healing': 519,\n",
       " 'bright': 520,\n",
       " 'acceptance': 521,\n",
       " 'powerful': 522,\n",
       " \"you'll\": 523,\n",
       " 'contagious': 524,\n",
       " 'set': 525,\n",
       " 'spreads': 526,\n",
       " 'wildfire': 527,\n",
       " 'sails': 528,\n",
       " 'fortress': 529,\n",
       " 'balm': 530,\n",
       " 'old': 531,\n",
       " 'sparks': 532,\n",
       " 'transcends': 533,\n",
       " 'all': 534,\n",
       " 'barriers': 535,\n",
       " 'drives': 536,\n",
       " 'ages': 537,\n",
       " 'powers': 538,\n",
       " 'conquer': 539,\n",
       " 'achieve': 540,\n",
       " 'difference': 541,\n",
       " 'adversity': 542,\n",
       " 'things': 543,\n",
       " 'agent': 544,\n",
       " 'anything': 545,\n",
       " 'melodies': 546,\n",
       " 'eyes': 547,\n",
       " 'deepest': 548,\n",
       " 'intentions': 549,\n",
       " 'away': 550,\n",
       " 'choices': 551,\n",
       " 'spread': 552,\n",
       " 'receive': 553,\n",
       " 'return': 554,\n",
       " 'makes': 555,\n",
       " 'grow': 556,\n",
       " 'plays': 557,\n",
       " 'watered': 558,\n",
       " 'renews': 559,\n",
       " 'sense': 560,\n",
       " 'forth': 561,\n",
       " 'differences': 562,\n",
       " 'resonate': 563,\n",
       " 'sowing': 564,\n",
       " 'lies': 565,\n",
       " 'freedom': 566,\n",
       " 'painting': 567,\n",
       " 'together': 568,\n",
       " 'truth': 569,\n",
       " 'rich': 570,\n",
       " 'waters': 571,\n",
       " 'transforms': 572,\n",
       " 'speak': 573,\n",
       " 'north': 574,\n",
       " 'which': 575,\n",
       " 'stand': 576,\n",
       " 'fire': 577,\n",
       " 'reflects': 578,\n",
       " 'infectious': 579,\n",
       " 'spreading': 580,\n",
       " 'sword': 581,\n",
       " 'cuts': 582,\n",
       " 'connections': 583,\n",
       " 'decision': 584,\n",
       " 'wellspring': 585,\n",
       " 'seas': 586,\n",
       " 'ripples': 587,\n",
       " 'preciousness': 588,\n",
       " 'uplift': 589,\n",
       " 'shapes': 590,\n",
       " 'between': 591,\n",
       " 'meet': 592,\n",
       " 'deserves': 593,\n",
       " 'becoming': 594,\n",
       " 'blossoming': 595,\n",
       " 'alter': 596,\n",
       " 'course': 597,\n",
       " 'reverberates': 598,\n",
       " 'stroke': 599,\n",
       " 'brush': 600,\n",
       " 'tale': 601,\n",
       " 'state': 602,\n",
       " 'contentment': 603,\n",
       " 'reside': 604,\n",
       " 'wide': 605,\n",
       " 'comes': 606,\n",
       " 'cultures': 607,\n",
       " 'bounds': 608,\n",
       " 'marina': 609,\n",
       " 'orchard': 610,\n",
       " \"sentosa's\": 611,\n",
       " 'corner': 612,\n",
       " 'merlion': 613,\n",
       " 'symbol': 614,\n",
       " 'timah': 615,\n",
       " 'reaches': 616,\n",
       " 'defines': 617,\n",
       " 'intertwine': 618,\n",
       " 'tells': 619,\n",
       " 'alive': 620,\n",
       " 'tales': 621,\n",
       " 'southern': 622,\n",
       " 'bird': 623,\n",
       " \"safari's\": 624,\n",
       " 'mysteries': 625,\n",
       " 'endeavor': 626,\n",
       " 'excellence': 627,\n",
       " 'changi': 628,\n",
       " 'vibrancy': 629,\n",
       " 'macritchie': 630,\n",
       " \"reservoir's\": 631,\n",
       " 'picture': 632,\n",
       " 'reaching': 633,\n",
       " 'diligence': 634,\n",
       " 'views': 635,\n",
       " 'embodies': 636,\n",
       " 'brand': 637,\n",
       " 'lake': 638,\n",
       " 'destinies': 639,\n",
       " 'chek': 640,\n",
       " \"jawa's\": 641,\n",
       " 'unwavering': 642,\n",
       " 'batok': 643,\n",
       " 'marine': 644,\n",
       " 'trove': 645,\n",
       " 'flourish': 646,\n",
       " 'stewardship': 647,\n",
       " 'forests': 648,\n",
       " 'breathe': 649,\n",
       " 'rivers': 650,\n",
       " 'skies': 651,\n",
       " 'cities': 652,\n",
       " 'footprint': 653,\n",
       " 'wetlands': 654,\n",
       " 'see': 655,\n",
       " 'drop': 656,\n",
       " \"earth's\": 657,\n",
       " 'savannas': 658,\n",
       " 'brushstrokes': 659,\n",
       " 'fiery': 660,\n",
       " 'pledge': 661,\n",
       " 'silent': 662,\n",
       " 'grass': 663,\n",
       " 'caves': 664,\n",
       " 'endurance': 665,\n",
       " 'renewal': 666,\n",
       " 'delicate': 667,\n",
       " 'ecosystems': 668,\n",
       " 'nurseries': 669,\n",
       " 'sand': 670,\n",
       " 'inhale': 671,\n",
       " 'veins': 672,\n",
       " 'land': 673,\n",
       " 'rising': 674,\n",
       " 'sun': 675,\n",
       " 'today': 676,\n",
       " 'presents': 677,\n",
       " 'reflect': 678,\n",
       " 'chambers': 679,\n",
       " 'soundtrack': 680,\n",
       " 'simple': 681,\n",
       " 'joys': 682,\n",
       " 'navigate': 683,\n",
       " 'illuminate': 684,\n",
       " 'fully': 685,\n",
       " 'reminding': 686,\n",
       " 'victories': 687,\n",
       " 'destination': 688,\n",
       " 'fingerprint': 689,\n",
       " 'exists': 690,\n",
       " 'silence': 691,\n",
       " 'speaks': 692,\n",
       " 'often': 693,\n",
       " 'significance': 694,\n",
       " 'constant': 695,\n",
       " 'chaos': 696,\n",
       " 'unknown': 697,\n",
       " 'midst': 698,\n",
       " 'peaceful': 699,\n",
       " 'elders': 700,\n",
       " 'allows': 701,\n",
       " 'sing': 702,\n",
       " 'turn': 703,\n",
       " 'off': 704,\n",
       " 'lands': 705,\n",
       " 'vulnerability': 706,\n",
       " 'ability': 707,\n",
       " 'itself': 708,\n",
       " 'without': 709,\n",
       " 'lullaby': 710,\n",
       " 'hug': 711,\n",
       " 'shadows': 712,\n",
       " 'expanding': 713,\n",
       " 'moon': 714,\n",
       " 'loving': 715,\n",
       " 'cannot': 716,\n",
       " 'affirmations': 717,\n",
       " 'solitude': 718,\n",
       " 'another': 719,\n",
       " 'raindrops': 720,\n",
       " 'nurture': 721,\n",
       " 'restore': 722,\n",
       " 'portrait': 723,\n",
       " 'radiates': 724,\n",
       " 'nurtures': 725,\n",
       " 'body': 726,\n",
       " 'deed': 727,\n",
       " 'restless': 728,\n",
       " 'balance': 729,\n",
       " 'gloomiest': 730,\n",
       " 'trust': 731,\n",
       " 'relationships': 732,\n",
       " 'minds': 733,\n",
       " 'attract': 734,\n",
       " 'great': 735,\n",
       " 'weight': 736,\n",
       " 'grudges': 737,\n",
       " 'keeps': 738,\n",
       " 'signature': 739,\n",
       " 'simplest': 740,\n",
       " 'anchor': 741,\n",
       " 'exploration': 742,\n",
       " 'smallest': 743,\n",
       " 'refuge': 744,\n",
       " 'weary': 745,\n",
       " 'bedrock': 746,\n",
       " 'generations': 747,\n",
       " 'unlocks': 748,\n",
       " 'mends': 749,\n",
       " 'unstoppable': 750,\n",
       " 'happen': 751,\n",
       " 'impossible': 752,\n",
       " 'think': 753,\n",
       " 'just': 754,\n",
       " 'as': 755,\n",
       " 'becomes': 756,\n",
       " 'conspire': 757,\n",
       " 'favor': 758,\n",
       " 'making': 759,\n",
       " 'footprints': 760,\n",
       " 'barrier': 761,\n",
       " 'forge': 762,\n",
       " 'limitless': 763,\n",
       " 'too': 764,\n",
       " 'unlock': 765,\n",
       " 'doors': 766,\n",
       " 'destined': 767,\n",
       " 'persevere': 768,\n",
       " 'darkness': 769,\n",
       " 'seek': 770,\n",
       " 'work': 771,\n",
       " 'art': 772,\n",
       " 'amazing': 773,\n",
       " 'limitation': 774,\n",
       " 'achieving': 775,\n",
       " 'architect': 776,\n",
       " 'brightest': 777,\n",
       " 'followed': 778,\n",
       " 'rainbows': 779,\n",
       " 'plant': 780,\n",
       " 'move': 781,\n",
       " 'points': 782,\n",
       " 'filled': 783,\n",
       " 'blend': 784,\n",
       " 'illuminated': 785,\n",
       " 'reflected': 786,\n",
       " 'multiply': 787,\n",
       " 'pieces': 788,\n",
       " 'unconditionally': 789,\n",
       " 'ink': 790,\n",
       " 'deeds': 791,\n",
       " 'calling': 792,\n",
       " 'disguise': 793,\n",
       " 'washes': 794,\n",
       " 'define': 795,\n",
       " 'forgive': 796,\n",
       " 'pen': 797,\n",
       " 'nudges': 798,\n",
       " 'triumphs': 799,\n",
       " 'choose': 800,\n",
       " 'found': 801,\n",
       " 'meaning': 802,\n",
       " 'ourselves': 803,\n",
       " 'guidance': 804,\n",
       " \"we've\": 805,\n",
       " 'traveled': 806,\n",
       " 'hopes': 807,\n",
       " 'offer': 808,\n",
       " 'pass': 809,\n",
       " 'uncertainty': 810,\n",
       " 'prelude': 811,\n",
       " 'savoring': 812,\n",
       " 'other': 813,\n",
       " 'side': 814,\n",
       " 'sweetest': 815,\n",
       " 'twist': 816,\n",
       " 'brightness': 817,\n",
       " 'notes': 818,\n",
       " 'tending': 819,\n",
       " 'steps': 820,\n",
       " 'limits': 821,\n",
       " 'lift': 822,\n",
       " 'weaves': 823,\n",
       " 'cultivating': 824,\n",
       " 'renew': 825,\n",
       " 'fruits': 826,\n",
       " 'pillars': 827,\n",
       " 'unveil': 828,\n",
       " 'weaving': 829,\n",
       " 'heights': 830,\n",
       " 'halls': 831,\n",
       " 'so': 832,\n",
       " 'brightly': 833,\n",
       " 'anthem': 834,\n",
       " 'against': 835,\n",
       " 'rock': 836,\n",
       " 'wildest': 837,\n",
       " 'binds': 838,\n",
       " 'wherever': 839,\n",
       " 'uplifts': 840,\n",
       " 'fear': 841,\n",
       " 'action': 842,\n",
       " 'stormy': 843,\n",
       " 'fosters': 844,\n",
       " 'achievements': 845,\n",
       " 'currency': 846,\n",
       " 'interactions': 847,\n",
       " 'unites': 848,\n",
       " 'principles': 849,\n",
       " 'engine': 850,\n",
       " 'contagion': 851,\n",
       " 'doubt': 852,\n",
       " 'salve': 853,\n",
       " 'turbulent': 854,\n",
       " 'protects': 855,\n",
       " 'values': 856,\n",
       " 'victory': 857,\n",
       " 'shared': 858,\n",
       " 'beam': 859,\n",
       " 'frees': 860,\n",
       " 'spoken': 861,\n",
       " 'counts': 862,\n",
       " 'thread': 863,\n",
       " 'human': 864,\n",
       " 'bad': 865,\n",
       " 'lesson': 866,\n",
       " 'embraced': 867,\n",
       " 'contented': 868,\n",
       " 'shown': 869,\n",
       " 'forged': 870,\n",
       " 'miracle': 871,\n",
       " 'fate': 872,\n",
       " 'mold': 873,\n",
       " 'glorious': 874,\n",
       " 'narrative': 875,\n",
       " 'farewells': 876,\n",
       " 'enlightenment': 877,\n",
       " 'out': 878,\n",
       " 'influence': 879,\n",
       " 'triumphant': 880,\n",
       " 'determined': 881,\n",
       " 'joyous': 882,\n",
       " 'worth': 883,\n",
       " 'telling': 884,\n",
       " 'ebb': 885,\n",
       " 'goodbyes': 886,\n",
       " 'transcending': 887,\n",
       " 'fostering': 888,\n",
       " 'serene': 889,\n",
       " 'blooming': 890,\n",
       " 'significant': 891,\n",
       " 'part': 892,\n",
       " 'turning': 893,\n",
       " 'point': 894,\n",
       " 'defy': 895,\n",
       " 'logic': 896,\n",
       " 'evolving': 897,\n",
       " 'wiser': 898,\n",
       " 'resilient': 899,\n",
       " 'version': 900,\n",
       " 'release': 901,\n",
       " 'resentment': 902,\n",
       " 'providing': 903,\n",
       " 'assurance': 904,\n",
       " 'not': 905,\n",
       " 'alone': 906,\n",
       " 'realization': 907,\n",
       " 'fulfillment': 908,\n",
       " 'richness': 909,\n",
       " 'meaningful': 910,\n",
       " 'connect': 911,\n",
       " 'affection': 912,\n",
       " 'deliberate': 913,\n",
       " 'shaping': 914,\n",
       " 'living': 915,\n",
       " 'proof': 916,\n",
       " 'conquering': 917,\n",
       " 'converge': 918,\n",
       " 'road': 919,\n",
       " 'roars': 920,\n",
       " 'embraces': 921,\n",
       " 'traditions': 922,\n",
       " 'reach': 923,\n",
       " 'beaches': 924,\n",
       " 'alleys': 925,\n",
       " 'southeast': 926,\n",
       " 'asia': 927,\n",
       " 'beats': 928,\n",
       " 'strong': 929,\n",
       " 'raffles': 930,\n",
       " 'place': 931,\n",
       " 'clarke': 932,\n",
       " 'quay': 933,\n",
       " 'told': 934,\n",
       " 'hawker': 935,\n",
       " 'centers': 936,\n",
       " 'fine': 937,\n",
       " 'dining': 938,\n",
       " 'flavors': 939,\n",
       " 'delectable': 940,\n",
       " 'ideas': 941,\n",
       " 'little': 942,\n",
       " \"india's\": 943,\n",
       " 'botanic': 944,\n",
       " 'glistens': 945,\n",
       " 'universal': 946,\n",
       " 'studios': 947,\n",
       " 'attractions': 948,\n",
       " 'class': 949,\n",
       " 'futures': 950,\n",
       " 'built': 951,\n",
       " 'park': 952,\n",
       " 'reserve': 953,\n",
       " 'heavens': 954,\n",
       " 'island': 955,\n",
       " \"road's\": 956,\n",
       " 'shopping': 957,\n",
       " 'shores': 958,\n",
       " 'trails': 959,\n",
       " 'leap': 960,\n",
       " 'sands': 961,\n",
       " 'flyer': 962,\n",
       " \"city's\": 963,\n",
       " 'landmarks': 964,\n",
       " 'lanterns': 965,\n",
       " 'kampong': 966,\n",
       " \"glam's\": 967,\n",
       " \"esplanade's\": 968,\n",
       " 'performances': 969,\n",
       " 'haw': 970,\n",
       " 'par': 971,\n",
       " \"villa's\": 972,\n",
       " 'culture': 973,\n",
       " 'thriving': 974,\n",
       " \"tekong's\": 975,\n",
       " \"islands'\": 976,\n",
       " 'testifies': 977,\n",
       " 'fort': 978,\n",
       " \"canning's\": 979,\n",
       " 'ruggedness': 980,\n",
       " 'dedication': 981,\n",
       " 'stone': 982,\n",
       " 'stretches': 983,\n",
       " 'horizon': 984,\n",
       " 'reign': 985,\n",
       " 'east': 986,\n",
       " 'coast': 987,\n",
       " 'breezes': 988,\n",
       " \"semakau's\": 989,\n",
       " 'talents': 990,\n",
       " 'honed': 991,\n",
       " 'peranakan': 992,\n",
       " 'houses': 993,\n",
       " 'colonial': 994,\n",
       " 'architecture': 995,\n",
       " 'preserved': 996,\n",
       " 'pride': 997,\n",
       " \"airport's\": 998,\n",
       " 'efficiency': 999,\n",
       " \"river's\": 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts(data)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embrace the beauty of every sunrise; it's a fresh chance to paint your world with joy.\n",
      "[[17, 148, 33, 20, 1, 373, 487, 10, 3, 374, 687]]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(tokenizer.texts_to_sequences([data[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "padded_sequences = pad_sequences(sequences, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(len(padded_sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 869), ('of', 663), ('your', 350), ('and', 322), ('a', 307), ('is', 253), ('in', 249), ('for', 201), ('let', 187), ('to', 180)]\n",
      "There are 1198 unique words.\n"
     ]
    }
   ],
   "source": [
    "word_freq = tokenizer.word_counts\n",
    "sorted_word_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_word_freq[:10])\n",
    "\n",
    "num_unique_words = len(tokenizer.word_index)\n",
    "print(f\"There are {num_unique_words} unique words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 890 Quotes and 1198 Unique Words. In those 890 quotes we have 869 'the' and 663 'of' it's very likely that the model we build will often predict those 2 phrases very often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal with 'the' and 'of'\n",
    "We can create new data, that is less biased towards the 'the' and 'of'.  \n",
    "Slice the quotes into different sizes and then train the model on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 2, 3 words\n",
    "phrases = []\n",
    "for quote in sequences:\n",
    "    for i in range(len(quote) - 1):\n",
    "        phrases.append(quote[i : i + 2])  # create 2-word phrases\n",
    "    for i in range(len(quote) - 2):\n",
    "        phrases.append(quote[i : i + 3])  # create 3-word phrases\n",
    "\n",
    "total_data = phrases + sequences\n",
    "max_sequence_len = max([len(x) for x in total_data])\n",
    "padded_sequences = pad_sequences(total_data, maxlen=max_sequence_len, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19458, 34)\n",
      "(19458, 1199)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = padded_sequences[:, :-1]\n",
    "labels = padded_sequences[:, -1]\n",
    "\n",
    "labels_encoded = tf.keras.utils.to_categorical(labels, num_classes=num_unique_words + 1)\n",
    "print(x_train.shape)\n",
    "print(labels_encoded.shape)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the inital model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model_LSTM():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_sequence_len - 1))\n",
    "    for i in range(2):\n",
    "        model.add(LSTM(150, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(tf.keras.layers.LayerNormalization())\n",
    "\n",
    "    model.add(LSTM(150, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(tf.keras.layers.LayerNormalization())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def first_model_GRU():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_sequence_len - 1))\n",
    "    for i in range(3):\n",
    "        model.add(GRU(150, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(tf.keras.layers.LayerNormalization())\n",
    "\n",
    "    model.add(GRU(150, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(tf.keras.layers.LayerNormalization())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def basic_rnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_sequence_len - 1))\n",
    "    model.add(SimpleRNN(150, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LayerNormalization())\n",
    "\n",
    "    model.add(SimpleRNN(150, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(tf.keras.layers.LayerNormalization())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "basic_rnn = basic_rnn_model()\n",
    "base_LSTM = first_model_LSTM()\n",
    "base_GRU = first_model_GRU()\n",
    "\n",
    "history_base_LSTM = model.fit(x_train,labels_encoded,batch_size=128,epochs=100,verbose=1,shuffle=True,\n",
    "    callbacks=[EarlyStopping(monitor=\"loss\", patience=3),\n",
    "        ModelCheckpoint(filepath=\"base_model_rnn.h5\", monitor=\"loss\", save_best_only=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_layers(number_layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_size, 50, input_length=max_sequence_len - 1))\n",
    "    for i in range(number_layers):\n",
    "        model.add(LSTM(100, return_sequences=True))\n",
    "        model.add(tf.keras.layers.LayerNormalization())\n",
    "\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(tf.keras.layers.LayerNormalization())\n",
    "    model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        labels_encoded,\n",
    "        batch_size=64,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(0, 5):\n",
    "    history_layers = tune_model_layers(i)\n",
    "    results.append({\n",
    "            \"layers\": i,\n",
    "            \"loss\": min(history_layers.history[\"loss\"]),\n",
    "            \"accuracy\": max(history_layers.history[\"accuracy\"]),\n",
    "        })\n",
    "    \n",
    "results_layers = pd.DataFrame(results)\n",
    "sns.lineplot(x=\"layers\", y=\"loss\", data=results_layers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_LSTM(lstm_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=max_sequence_len - 1))\n",
    "    for i in range(1):\n",
    "        model.add(LSTM(lstm_size, return_sequences=True))\n",
    "        model.add(tf.keras.layers.LayerNormalization())\n",
    "        \n",
    "    model.add(LSTM(lstm_size, return_sequences=False))\n",
    "    model.add(tf.keras.layers.LayerNormalization())\n",
    "    model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        labels_encoded,\n",
    "        batch_size=64,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"loss\", patience=10, min_delta=0.0001, restore_best_weights=True\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(30,120,10):\n",
    "    history_layers = tune_model_LSTM(i)\n",
    "    results.append({\n",
    "            \"units\": i,\n",
    "            \"loss\": min(history_layers.history[\"loss\"]),\n",
    "            \"accuracy\": max(history_layers.history[\"accuracy\"]),\n",
    "        })\n",
    "results_units = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='units', y=\"loss\", data=results_units)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=max_sequence_len - 1))\n",
    "    for i in range(1):\n",
    "        model.add(LSTM(100, return_sequences=True))\n",
    "        model.add(tf.keras.layers.LayerNormalization())\n",
    "        \n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(tf.keras.layers.LayerNormalization())\n",
    "    model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = final_model()\n",
    "final_model.fit(\n",
    "    X,\n",
    "    labels_encoded,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10, min_delta=0.0001, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"final_model.h5\", monitor=\"loss\", save_best_only=True, verbose=1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_N_words_unique(seed_texts, top_p=1, N_words=10):\n",
    "    generated_texts = []\n",
    "\n",
    "    for seed_text in seed_texts:\n",
    "        current_generated_text = seed_text\n",
    "        for i in range(N_words):\n",
    "            seed_sequence = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([seed_sequence], maxlen=max_sequence_len - 1)\n",
    "            predictions = final_model.predict(padded_sequence, verbose=0)[0]\n",
    "\n",
    "            sorted_indices = np.argsort(predictions)[::-1]\n",
    "            cumulative_probs = np.cumsum(predictions[sorted_indices])\n",
    "            selected_indices = sorted_indices[cumulative_probs <= top_p]\n",
    "\n",
    "            selected_probs = predictions[selected_indices] / np.sum(\n",
    "                predictions[selected_indices]\n",
    "            )\n",
    "\n",
    "            next_index = np.random.choice(selected_indices, p=selected_probs)\n",
    "            next_word = tokenizer.index_word[next_index]\n",
    "\n",
    "            if (\n",
    "                next_word is None\n",
    "                or next_word == \"end_token\"\n",
    "                or len(current_generated_text.split()) >= N_words + len(seed_text)\n",
    "            ):\n",
    "                break\n",
    "\n",
    "            current_generated_text += \" \" + next_word\n",
    "            seed_text += \" \" + next_word\n",
    "\n",
    "        generated_texts.append(current_generated_text)\n",
    "    return generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_texts = [\n",
    "    \"embrace each day\",\n",
    "    \"radiate some\",\n",
    "    \"believe that\",\n",
    "    \"life's actual purpose is\",\n",
    "    \"dance through each and every\",\n",
    "    \"let your time and energy\",\n",
    "    \"every person is\",\n",
    "    \"our country Singapore is\",\n",
    "    \"planet earth is\",\n",
    "    \"morning and evening would make it\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_texts = predict_next_N_words_unique(seed_texts)\n",
    "for text in predicted_texts:\n",
    "    print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
